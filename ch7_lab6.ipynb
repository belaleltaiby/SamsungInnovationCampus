{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97038601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRIM: double (nullable = true)\n",
      " |-- ZN: double (nullable = true)\n",
      " |-- INDUS: double (nullable = true)\n",
      " |-- CHAS: string (nullable = true)\n",
      " |-- NOX: double (nullable = true)\n",
      " |-- RM: double (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- DIS: double (nullable = true)\n",
      " |-- RAD: integer (nullable = true)\n",
      " |-- TAX: integer (nullable = true)\n",
      " |-- PTRATIO: double (nullable = true)\n",
      " |-- B: double (nullable = true)\n",
      " |-- LSTAT: double (nullable = true)\n",
      " |-- MEDV: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Housing DataFrame\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "housing_df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"/user/student/housing.csv\")\n",
    "\n",
    "# Inspect the schema of the DataFrame\n",
    "housing_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc96b617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM|  AGE|   DIS|RAD|TAX|PTRATIO|     B|LSTAT|MEDV|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575| 65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421| 78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|6.421| 78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998| 45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147| 54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n",
      "|0.02985| 0.0| 2.18|   0|0.458| 6.43| 58.7|6.0622|  3|222|   18.7|394.12| 5.21|28.7|\n",
      "|0.08829|12.5| 7.87|null|0.524|6.012| 66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|\n",
      "|0.14455|12.5| 7.87|   0|0.524|6.172| 96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|\n",
      "|0.21124|12.5| 7.87|   0|0.524|5.631|100.0|6.0821|  5|311|   15.2|386.63|29.93|16.5|\n",
      "|0.17004|12.5| 7.87|   0|0.524|6.004| 85.9|6.5921|  5|311|   15.2|386.71| 17.1|20.2|\n",
      "|0.22489|12.5| 7.87|   0|0.524|6.377| 94.3|6.3467|  5|311|   15.2|392.52|20.45|18.5|\n",
      "|0.11747|12.5| 7.87|   0|0.524|6.009| 82.9|6.2267|  5|311|   15.2| 390.5|13.27|20.9|\n",
      "|0.09378|12.5| 7.87|   0|0.524|5.889| 39.0|5.4509|  5|311|   15.2| 390.5|15.71|21.7|\n",
      "|0.62976| 0.0| 8.14|null|0.538|5.949| 61.8|4.7075|  4|307|   21.0| 396.9| 8.26|23.1|\n",
      "|0.63796| 0.0| 8.14|   0|0.538|6.096| 84.5|4.4619|  4|307|   21.0|380.02|10.26|23.8|\n",
      "|1.05393| 0.0| 8.14|   0|0.538|5.935| 29.3|4.4986|  4|307|   21.0|386.85| 6.58|22.7|\n",
      "| 0.7842| 0.0| 8.14|   0|0.538| 5.99| 81.7|4.2579|  4|307|   21.0|386.75|14.67|27.5|\n",
      "|0.80271| 0.0| 8.14|   0|0.538|5.456| 36.6|3.7965|  4|307|   21.0|288.99|11.69|20.8|\n",
      "| 0.7258| 0.0| 8.14|   0|0.538|5.727| 69.5|3.7965|  4|307|   21.0|390.95|11.28|18.2|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aff8759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[CRIM: double, ZN: double, INDUS: double, CHAS: string, NOX: double, RM: double, AGE: double, DIS: double, RAD: int, TAX: int, PTRATIO: double, B: double, LSTAT: double, MEDV: double]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0e47d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all columns\n",
    "all_columns = housing_df.columns\n",
    "\n",
    "# Create a list excluding the 'MEDV' column\n",
    "feature_columns = [col for col in all_columns if col != \"MEDV\"]\n",
    "\n",
    "# Print the list of feature columns\n",
    "print(feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b48bf218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d09634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+\n",
      "|features                                                                    |\n",
      "+----------------------------------------------------------------------------+\n",
      "|[0.00632,18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98]     |\n",
      "|[0.02731,0.0,7.07,0.0,0.469,6.421,78.9,4.9671,2.0,242.0,17.8,396.9,9.14]    |\n",
      "|[0.02729,0.0,7.07,0.0,0.469,6.421,78.9,4.9671,2.0,242.0,17.8,396.9,9.14]    |\n",
      "|[0.03237,0.0,2.18,0.0,0.458,6.998,45.8,6.0622,3.0,222.0,18.7,394.63,2.94]   |\n",
      "|[0.06905,0.0,2.18,0.0,0.458,7.147,54.2,6.0622,3.0,222.0,18.7,396.9,5.33]    |\n",
      "|[0.02985,0.0,2.18,0.0,0.458,6.43,58.7,6.0622,3.0,222.0,18.7,394.12,5.21]    |\n",
      "|[0.08829,12.5,7.87,1.0,0.524,6.012,66.6,5.5605,5.0,311.0,15.2,395.6,12.43]  |\n",
      "|[0.14455,12.5,7.87,0.0,0.524,6.172,96.1,5.9505,5.0,311.0,15.2,396.9,19.15]  |\n",
      "|[0.21124,12.5,7.87,0.0,0.524,5.631,100.0,6.0821,5.0,311.0,15.2,386.63,29.93]|\n",
      "|[0.17004,12.5,7.87,0.0,0.524,6.004,85.9,6.5921,5.0,311.0,15.2,386.71,17.1]  |\n",
      "|[0.22489,12.5,7.87,0.0,0.524,6.377,94.3,6.3467,5.0,311.0,15.2,392.52,20.45] |\n",
      "|[0.11747,12.5,7.87,0.0,0.524,6.009,82.9,6.2267,5.0,311.0,15.2,390.5,13.27]  |\n",
      "|[0.09378,12.5,7.87,0.0,0.524,5.889,39.0,5.4509,5.0,311.0,15.2,390.5,15.71]  |\n",
      "|[0.62976,0.0,8.14,1.0,0.538,5.949,61.8,4.7075,4.0,307.0,21.0,396.9,8.26]    |\n",
      "|[0.63796,0.0,8.14,0.0,0.538,6.096,84.5,4.4619,4.0,307.0,21.0,380.02,10.26]  |\n",
      "|[1.05393,0.0,8.14,0.0,0.538,5.935,29.3,4.4986,4.0,307.0,21.0,386.85,6.58]   |\n",
      "|[0.7842,0.0,8.14,0.0,0.538,5.99,81.7,4.2579,4.0,307.0,21.0,386.75,14.67]    |\n",
      "|[0.80271,0.0,8.14,0.0,0.538,5.456,36.6,3.7965,4.0,307.0,21.0,288.99,11.69]  |\n",
      "|[0.7258,0.0,8.14,0.0,0.538,5.727,69.5,3.7965,4.0,307.0,21.0,390.95,11.28]   |\n",
      "+----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembled_df = assembler.transform(housing_df_indexed)\n",
    "\n",
    "\n",
    "assembled_df.select(\"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6110bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights = [0.7, 0.3] \n",
    "train, test = assembled_df.randomSplit(weights) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92180128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 05:02:34,337 WARN util.Instrumentation: [63e6714a] regParam is zero, which might cause numerical instability and overfitting.\n",
      "2024-10-01 05:02:34,899 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2024-10-01 05:02:34,900 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "2024-10-01 05:02:34,973 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "2024-10-01 05:02:34,973 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "2024-10-01 05:02:35,048 WARN util.Instrumentation: [63e6714a] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "2024-10-01 05:02:36,342 ERROR optimize.LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search zoom failed\n",
      "2024-10-01 05:02:36,345 ERROR optimize.LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search zoom failed\n",
      "2024-10-01 05:02:36,347 ERROR optimize.LBFGS: Failure again! Giving up and returning. Maybe the objective is just poorly behaved?\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# 3.1 Create a Linear Regression Estimator\n",
    "lr = LinearRegression(featuresCol='features', labelCol='MEDV')\n",
    "\n",
    "# 3.2 Fit the model on the training set\n",
    "lr_model = lr.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ddf8c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions DataFrame:\n",
      "+--------------------------------------------------------------------------+----+------------------+\n",
      "|features                                                                  |MEDV|prediction        |\n",
      "+--------------------------------------------------------------------------+----+------------------+\n",
      "|[0.00632,18.0,2.31,0.0,0.538,6.575,65.2,4.09,1.0,296.0,15.3,396.9,4.98]   |24.0|4.207161825791275 |\n",
      "|[0.02729,0.0,7.07,0.0,0.469,6.421,78.9,4.9671,2.0,242.0,17.8,396.9,9.14]  |21.6|21.60075314695348 |\n",
      "|[0.03237,0.0,2.18,0.0,0.458,6.998,45.8,6.0622,3.0,222.0,18.7,394.63,2.94] |33.4|35.34298822791544 |\n",
      "|[0.08829,12.5,7.87,1.0,0.524,6.012,66.6,5.5605,5.0,311.0,15.2,395.6,12.43]|22.9|5.856243806697023 |\n",
      "|[0.14455,12.5,7.87,0.0,0.524,6.172,96.1,5.9505,5.0,311.0,15.2,396.9,19.15]|27.1|18.937742182308227|\n",
      "+--------------------------------------------------------------------------+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = lr_model.transform(test)\n",
    "\n",
    "print(\"Predictions DataFrame:\")\n",
    "predictions.select('features', 'MEDV', 'prediction').show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60743ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions DataFrame:\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+------------------+\n",
      "|CRIM   |ZN  |INDUS|CHAS|NOX  |RM   |AGE |DIS   |RAD|TAX|PTRATIO|B     |LSTAT|MEDV|prediction        |\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+------------------+\n",
      "|0.00632|18.0|2.31 |0   |0.538|6.575|65.2|4.09  |1  |296|15.3   |396.9 |4.98 |24.0|4.207161825791275 |\n",
      "|0.02729|0.0 |7.07 |0   |0.469|6.421|78.9|4.9671|2  |242|17.8   |396.9 |9.14 |21.6|21.60075314695348 |\n",
      "|0.03237|0.0 |2.18 |0   |0.458|6.998|45.8|6.0622|3  |222|18.7   |394.63|2.94 |33.4|35.34298822791544 |\n",
      "|0.08829|12.5|7.87 |null|0.524|6.012|66.6|5.5605|5  |311|15.2   |395.6 |12.43|22.9|5.856243806697023 |\n",
      "|0.14455|12.5|7.87 |0   |0.524|6.172|96.1|5.9505|5  |311|15.2   |396.9 |19.15|27.1|18.937742182308227|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = lr_model.transform(test)\n",
    "\n",
    "\n",
    "print(\"Predictions DataFrame:\")\n",
    "predictions.select('CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV', 'prediction').show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df1234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
