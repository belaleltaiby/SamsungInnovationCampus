{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dab7797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 23:05:58,805 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2024-08-31 23:05:58,806 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2024-08-31 23:06:01,611 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- birthdate: string (nullable = true)\n",
      " |-- added: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+----------+--------------------+\n",
      "| id|first_name| last_name|               email| birthdate|               added|\n",
      "+---+----------+----------+--------------------+----------+--------------------+\n",
      "|  1|    Walton|     Adams|barmstrong@exampl...|1989-03-01|1997-01-02 04:18:...|\n",
      "|  2|  Marietta|     Walsh|hand.stella@examp...|2018-05-30|2010-08-26 18:20:...|\n",
      "|  3|      Lily|Wintheiser|darren.blanda@exa...|1981-08-21|1973-06-11 07:28:...|\n",
      "|  4|   Estevan|   Gleason|shanahan.aliyah@e...|2013-07-17|1995-01-29 16:08:...|\n",
      "|  5|  Thaddeus|      Rowe|bednar.robin@exam...|2019-02-26|2017-01-05 04:13:...|\n",
      "|  6|    Cortez|    Russel|kennedi.stokes@ex...|1977-06-14|2007-03-02 10:19:...|\n",
      "|  7|     Deion|     Yundt|lindgren.timmy@ex...|1970-09-02|1988-06-22 16:18:...|\n",
      "|  8|  Caterina|Cartwright|lschroeder@exampl...|1986-10-04|2001-08-05 00:39:...|\n",
      "|  9|     Rylee|     Morar|barton.wuckert@ex...|2003-11-23|1991-09-23 17:09:...|\n",
      "| 10|    Dewitt|   Smitham|  yfadel@example.org|1995-12-17|1997-05-09 04:35:...|\n",
      "+---+----------+----------+--------------------+----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "authorsDF = spark.sql(\"select * from mydb.authors limit 10\")\n",
    "authorsDF.printSchema()\n",
    "authorsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca92816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n",
      "+----------+----------+---------------------------+\n",
      "|first_name|last_name |email                      |\n",
      "+----------+----------+---------------------------+\n",
      "|Lily      |Wintheiser|darren.blanda@example.org  |\n",
      "|Dewitt    |Smitham   |yfadel@example.org         |\n",
      "|Willard   |Wilderman |virgil45@example.org       |\n",
      "|Jazlyn    |Osinski   |philip.schaden@example.org |\n",
      "|America   |Marquardt |ulockman@example.org       |\n",
      "|Alvis     |Crist     |kennith25@example.org      |\n",
      "|Thurman   |Lesch     |mauricio.harris@example.org|\n",
      "|Tad       |Bechtelar |jada.grant@example.org     |\n",
      "|Dudley    |Kirlin    |lauretta82@example.org     |\n",
      "|Marcelino |Tremblay  |lenora.fritsch@example.org |\n",
      "+----------+----------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "authorsDF = spark.sql(\"\"\" select first_name, last_name,email \n",
    "                          from mydb.authors\n",
    "                          where email like '%org'\n",
    "                          limit 10\"\"\")\n",
    "authorsDF.printSchema()\n",
    "authorsDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e743850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- birthdate: string (nullable = true)\n",
      "\n",
      "+----------+---------+----------+\n",
      "|first_name|last_name|birthdate |\n",
      "+----------+---------+----------+\n",
      "|Marietta  |Walsh    |2018-05-30|\n",
      "|Estevan   |Gleason  |2013-07-17|\n",
      "|Thaddeus  |Rowe     |2019-02-26|\n",
      "|Rylee     |Morar    |2003-11-23|\n",
      "|Skye      |Powlowski|2012-08-26|\n",
      "|Brenda    |Mayer    |2015-03-10|\n",
      "|Raina     |Volkman  |2007-05-03|\n",
      "|Dahlia    |Wiegand  |2005-09-29|\n",
      "|Doyle     |Fay      |2004-03-11|\n",
      "|Beaulah   |Jaskolski|2005-06-27|\n",
      "+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.3\n",
    "authorsDF = spark.sql(\"\"\"select first_name, last_name,birthdate\n",
    "                         from mydb.authors\n",
    "                         where birthdate >= '2000-01-01' \n",
    "                         limit 10\"\"\")\n",
    "\n",
    "authorsDF.printSchema()\n",
    "authorsDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9848ca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+------------+-------------+---------+---------+--------+------------+----------+-----------+\n",
      "|              Region|Country|  ItemType|SalesChannel|OrderPriority|UnitsSold|UnitPrice|UnitCost|TotalRevenue| TotalCost|TotalProfit|\n",
      "+--------------------+-------+----------+------------+-------------+---------+---------+--------+------------+----------+-----------+\n",
      "|Middle East and N...|  Libya| Cosmetics|     Offline|            M|     8446|    437.2|  263.33|   3692591.2|2224085.18| 1468506.02|\n",
      "|       North America| Canada|Vegetables|      Online|            M|     3018|   154.06|   90.93|   464953.08| 274426.74|  190526.34|\n",
      "|Middle East and N...|  Libya| Baby Food|     Offline|            C|     1517|   255.28|  159.42|   387259.76| 241840.14|  145419.62|\n",
      "|                Asia|  Japan|    Cereal|     Offline|            C|     3322|    205.7|  117.11|    683335.4| 389039.42|  294295.98|\n",
      "|  Sub-Saharan Africa|   Chad|    Fruits|     Offline|            H|     9845|     9.33|    6.92|    91853.85|   68127.4|   23726.45|\n",
      "+--------------------+-------+----------+------------+-------------+---------+---------+--------+------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salesDF = spark.read.option(\"header\",\"true\").csv(\"sales.csv\")\n",
    "salesDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a58b910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesDF.createOrReplaceTempView(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa8aeb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 00:00:33,818 WARN metastore.ObjectStore: Failed to get database json, returning NoSuchObjectException\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|author_id|         phone_model|\n",
      "+---------+--------------------+\n",
      "|        1|Samsung Galaxy s2...|\n",
      "|        2| Samsung Galaxy A52s|\n",
      "|        3|Samsung Galaxy Z ...|\n",
      "|        4|      Apple iPhone 7|\n",
      "|        5|     Apple iPhone 11|\n",
      "|        6|  Samsung Galaxy A12|\n",
      "|        7|Samsung Galaxy A5...|\n",
      "|        8| Samsung Galaxy A52s|\n",
      "|        9|Samsung Galaxy No...|\n",
      "|       10|                    |\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "authorPhoneDF= spark.sql(\"\"\" SELECT * FROM \n",
    " json.`/user/student/author_phone.json` \n",
    " LIMIT 10 \"\"\") \n",
    "\n",
    "authorPhoneDF.createOrReplaceTempView(\"author_phone\")\n",
    "authorPhoneDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97cd56fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sparksql-magic in ./.local/lib/python3.8/site-packages (0.0.3)\n",
      "Requirement already satisfied: pyspark>=2.3.0 in /usr/local/spark3/spark-3.1.2-bin-hadoop3.2/python (from sparksql-magic) (3.1.2)\n",
      "Requirement already satisfied: ipython>=7.4.0 in /usr/local/lib/python3.8/site-packages (from sparksql-magic) (7.26.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (56.0.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (0.18.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (5.0.9)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (5.0.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (3.0.19)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (2.10.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (0.1.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/site-packages (from ipython>=7.4.0->sparksql-magic) (4.8.0)\n",
      "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.8/site-packages (from pyspark>=2.3.0->sparksql-magic) (0.10.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.4.0->sparksql-magic) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.4.0->sparksql-magic) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.4.0->sparksql-magic) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/site-packages (from traitlets>=4.2->ipython>=7.4.0->sparksql-magic) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "!pip install sparksql-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79166c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparksql_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext sparksql_magic\n"
     ]
    }
   ],
   "source": [
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a77f0525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">id</td><td style=\"font-weight: bold\">first_name</td><td style=\"font-weight: bold\">last_name</td><td style=\"font-weight: bold\">email</td><td style=\"font-weight: bold\">birthdate</td><td style=\"font-weight: bold\">added</td></tr><tr><td>1</td><td>Walton</td><td>Adams</td><td>barmstrong@example.com</td><td>1989-03-01</td><td>1997-01-02 04:18:41.0</td></tr><tr><td>2</td><td>Marietta</td><td>Walsh</td><td>hand.stella@example.net</td><td>2018-05-30</td><td>2010-08-26 18:20:14.0</td></tr><tr><td>3</td><td>Lily</td><td>Wintheiser</td><td>darren.blanda@example.org</td><td>1981-08-21</td><td>1973-06-11 07:28:12.0</td></tr><tr><td>4</td><td>Estevan</td><td>Gleason</td><td>shanahan.aliyah@example.net</td><td>2013-07-17</td><td>1995-01-29 16:08:31.0</td></tr><tr><td>5</td><td>Thaddeus</td><td>Rowe</td><td>bednar.robin@example.net</td><td>2019-02-26</td><td>2017-01-05 04:13:48.0</td></tr><tr><td>6</td><td>Cortez</td><td>Russel</td><td>kennedi.stokes@example.com</td><td>1977-06-14</td><td>2007-03-02 10:19:18.0</td></tr><tr><td>7</td><td>Deion</td><td>Yundt</td><td>lindgren.timmy@example.com</td><td>1970-09-02</td><td>1988-06-22 16:18:23.0</td></tr><tr><td>8</td><td>Caterina</td><td>Cartwright</td><td>lschroeder@example.com</td><td>1986-10-04</td><td>2001-08-05 00:39:02.0</td></tr><tr><td>9</td><td>Rylee</td><td>Morar</td><td>barton.wuckert@example.net</td><td>2003-11-23</td><td>1991-09-23 17:09:22.0</td></tr><tr><td>10</td><td>Dewitt</td><td>Smitham</td><td>yfadel@example.org</td><td>1995-12-17</td><td>1997-05-09 04:35:50.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "select * from mydb.authors limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "839ba5af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- birthdate: string (nullable = true)\n",
      " |-- added: string (nullable = true)\n",
      "\n",
      "+---+----------+----------+--------------------+----------+--------------------+\n",
      "| id|first_name| last_name|               email| birthdate|               added|\n",
      "+---+----------+----------+--------------------+----------+--------------------+\n",
      "|  1|    Walton|     Adams|barmstrong@exampl...|1989-03-01|1997-01-02 04:18:...|\n",
      "|  2|  Marietta|     Walsh|hand.stella@examp...|2018-05-30|2010-08-26 18:20:...|\n",
      "|  3|      Lily|Wintheiser|darren.blanda@exa...|1981-08-21|1973-06-11 07:28:...|\n",
      "|  4|   Estevan|   Gleason|shanahan.aliyah@e...|2013-07-17|1995-01-29 16:08:...|\n",
      "|  5|  Thaddeus|      Rowe|bednar.robin@exam...|2019-02-26|2017-01-05 04:13:...|\n",
      "|  6|    Cortez|    Russel|kennedi.stokes@ex...|1977-06-14|2007-03-02 10:19:...|\n",
      "|  7|     Deion|     Yundt|lindgren.timmy@ex...|1970-09-02|1988-06-22 16:18:...|\n",
      "|  8|  Caterina|Cartwright|lschroeder@exampl...|1986-10-04|2001-08-05 00:39:...|\n",
      "|  9|     Rylee|     Morar|barton.wuckert@ex...|2003-11-23|1991-09-23 17:09:...|\n",
      "| 10|    Dewitt|   Smitham|  yfadel@example.org|1995-12-17|1997-05-09 04:35:...|\n",
      "+---+----------+----------+--------------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "authorsDF = spark.sql(\"select * from mydb.authors limit 10\")\n",
    "authorsDF.printSchema()\n",
    "authorsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de8deac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinDF = authorsDF.join(authorPhoneDF,authorsDF.id == authorPhoneDF.author_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "207061c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|first_name| last_name|         phone_model|\n",
      "+----------+----------+--------------------+\n",
      "|    Walton|     Adams|Samsung Galaxy s2...|\n",
      "|  Marietta|     Walsh| Samsung Galaxy A52s|\n",
      "|      Lily|Wintheiser|Samsung Galaxy Z ...|\n",
      "|   Estevan|   Gleason|      Apple iPhone 7|\n",
      "|  Thaddeus|      Rowe|     Apple iPhone 11|\n",
      "|    Cortez|    Russel|  Samsung Galaxy A12|\n",
      "|     Deion|     Yundt|Samsung Galaxy A5...|\n",
      "|  Caterina|Cartwright| Samsung Galaxy A52s|\n",
      "|     Rylee|     Morar|Samsung Galaxy No...|\n",
      "|    Dewitt|   Smitham|                    |\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select a.first_name,a.last_name, b.phone_model\n",
    "            from mydb.authors a\n",
    "            join author_phone b\n",
    "            on a.id = b.author_id\n",
    "            limit 10\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a5b22d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">first_name</td><td style=\"font-weight: bold\">last_name</td><td style=\"font-weight: bold\">phone_model</td><td style=\"font-weight: bold\">birthdate</td></tr><tr><td>Dewitt</td><td>Smitham</td><td></td><td>1995-12-17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "select a.first_name, a.last_name, b.phone_model, a.birthdate\n",
    "    from mydb.authors a\n",
    "    join author_phone b\n",
    "    on a.id = b.author_id\n",
    "    where b.phone_model = \"\"\n",
    "    order By a.birthdate DESC\n",
    "    LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff8e735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9882dd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">namespace</td></tr><tr><td>default</td></tr><tr><td>mydb</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "\n",
    "show DATABASES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6aa88609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE mydb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13dd43cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----------+\n",
      "|database|        tableName|isTemporary|\n",
      "+--------+-----------------+-----------+\n",
      "|    mydb|      author_bday|      false|\n",
      "|    mydb|          authors|      false|\n",
      "|    mydb| authors_parquet2|      false|\n",
      "|    mydb|             cars|      false|\n",
      "|    mydb|      celebrities|      false|\n",
      "|    mydb|       continents|      false|\n",
      "|    mydb|        countries|      false|\n",
      "|    mydb|employee_salaries|      false|\n",
      "|    mydb|            posts|      false|\n",
      "|        |     author_phone|       true|\n",
      "|        |            sales|       true|\n",
      "+--------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d68bb8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 00:11:23,922 WARN analysis.ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "2024-09-01 00:11:24,193 WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "2024-09-01 00:11:24,404 WARN conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "2024-09-01 00:11:24,404 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2024-09-01 00:11:24,405 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2024-09-01 00:11:24,440 WARN metastore.HiveMetaStore: Location: hdfs://localhost:9000/user/hive/warehouse/mydb.db/spark_test specified for non-external table:spark_test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "CREATE TABLE spark_test(\n",
    "    name string,\n",
    "    age int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d88c53fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                   |comment|\n",
      "+----------------------------+------------------------------------------------------------+-------+\n",
      "|name                        |string                                                      |null   |\n",
      "|age                         |int                                                         |null   |\n",
      "|                            |                                                            |       |\n",
      "|# Detailed Table Information|                                                            |       |\n",
      "|Database                    |mydb                                                        |       |\n",
      "|Table                       |spark_test                                                  |       |\n",
      "|Owner                       |student                                                     |       |\n",
      "|Created Time                |Sun Sep 01 00:11:24 KST 2024                                |       |\n",
      "|Last Access                 |UNKNOWN                                                     |       |\n",
      "|Created By                  |Spark 3.1.2                                                 |       |\n",
      "|Type                        |MANAGED                                                     |       |\n",
      "|Provider                    |hive                                                        |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1725117084]                          |       |\n",
      "|Location                    |hdfs://localhost:9000/user/hive/warehouse/mydb.db/spark_test|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe          |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                    |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat  |       |\n",
      "|Storage Properties          |[serialization.format=1]                                    |       |\n",
      "|Partition Provider          |Catalog                                                     |       |\n",
      "+----------------------------+------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESC FORMATTED spark_test\").show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1edb69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "INSERt INTO spark_test VALUES (\"Henry\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f537dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">name</td><td style=\"font-weight: bold\">age</td></tr><tr><td>Henry</td><td>10</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "select * from spark_test;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0263fefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\" ALTER TABLE spark_test \n",
    " ADD COLUMNS (gender string) \"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f14dadf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 36:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark.sql(\"\"\"ALTER TABLE spark_test ADD COLUMNS (gender STRING)\"\"\")\n",
    "spark.sql(\"\"\"INSERT INTO spark_test VALUES (\"Shaun\", 42, \"Male\")\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b3c7eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"><td style=\"font-weight: bold\">name</td><td style=\"font-weight: bold\">age</td><td style=\"font-weight: bold\">gender</td></tr><tr><td>Henry</td><td>10</td><td>null</td></tr><tr><td>Shaun</td><td>42</td><td>Male</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "select * from spark_test;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff33a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33189f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database(name='default', description='Default Hive database', locationUri='hdfs://localhost:9000/user/hive/warehouse')\n",
      "Database(name='mydb', description='', locationUri='hdfs://localhost:9000/user/hive/warehouse/mydb.db')\n"
     ]
    }
   ],
   "source": [
    "for db in spark.catalog.listDatabases():\n",
    "    print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "108d335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|     mydb|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6c75c031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table(name='author_bday', database='mydb', description=None, tableType='MANAGED', isTemporary=False)\n",
      "Table(name='authors', database='mydb', description='Imported by sqoop on 2024/08/29 07:49:42', tableType='MANAGED', isTemporary=False)\n",
      "Table(name='authors_parquet2', database='mydb', description=None, tableType='EXTERNAL', isTemporary=False)\n",
      "Table(name='cars', database='mydb', description=None, tableType='MANAGED', isTemporary=False)\n",
      "Table(name='celebrities', database='mydb', description='Imported by sqoop on 2024/08/25 09:56:52', tableType='MANAGED', isTemporary=False)\n",
      "Table(name='continents', database='mydb', description=None, tableType='EXTERNAL', isTemporary=False)\n",
      "Table(name='countries', database='mydb', description='Imported by sqoop on 2024/08/25 10:43:25', tableType='MANAGED', isTemporary=False)\n",
      "Table(name='employee_salaries', database='mydb', description=None, tableType='MANAGED', isTemporary=False)\n",
      "Table(name='posts', database='mydb', description='Imported by sqoop on 2024/08/25 04:31:52', tableType='MANAGED', isTemporary=False)\n",
      "Table(name='spark_test', database='mydb', description=None, tableType='MANAGED', isTemporary=False)\n",
      "Table(name='author_phone', database=None, description=None, tableType='TEMPORARY', isTemporary=True)\n",
      "Table(name='sales', database=None, description=None, tableType='TEMPORARY', isTemporary=True)\n"
     ]
    }
   ],
   "source": [
    "spark.catalog.setCurrentDatabase(\"mydb\")\n",
    "for tb in spark.catalog.listTables():\n",
    "    print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15098c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-----------+\n",
      "|database|        tableName|isTemporary|\n",
      "+--------+-----------------+-----------+\n",
      "|    mydb|      author_bday|      false|\n",
      "|    mydb|          authors|      false|\n",
      "|    mydb| authors_parquet2|      false|\n",
      "|    mydb|             cars|      false|\n",
      "|    mydb|      celebrities|      false|\n",
      "|    mydb|       continents|      false|\n",
      "|    mydb|        countries|      false|\n",
      "|    mydb|employee_salaries|      false|\n",
      "|    mydb|            posts|      false|\n",
      "|    mydb|       spark_test|      false|\n",
      "|        |     author_phone|       true|\n",
      "|        |            sales|       true|\n",
      "+--------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Use mydb\")\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6bc91907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column(name='id', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='first_name', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='last_name', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='email', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='birthdate', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
       " Column(name='added', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listColumns(\"authors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee02c3",
   "metadata": {},
   "source": [
    "# Chapter 6 - Lab 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad97e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf12648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
